{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HF_28ym_asVxhS4lBxmiblpgzxodkn6P",
      "authorship_tag": "ABX9TyOEBQAFKeK0uYkEVfbH/Pr3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sai5979/sai-revanth/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz2aGVSbDD_B",
        "outputId": "eb4a5c20-b3a8-44b5-d214-5a742a7fc35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjEq1nE_FtC0",
        "outputId": "1eb37e3e-8d7e-4e0e-851f-ec8daaf6bed7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install  scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYIsu9zlGlbc",
        "outputId": "fe77039e-c1a0-4dbd-fafd-2e9c83e19faf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WW2oN6YGtyc",
        "outputId": "e675a33d-3ce6-4801-c912-e2f7e2706eb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=4ce6ad106642224905d2649daec45c5e2228b841cb82bc4e3acd44221f9567de\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install import_ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDO1LVugG6_G",
        "outputId": "0f52a3ab-46b1-4ef6-ee71-f18c3e50cefe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting import_ipynb\n",
            "  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (5.7.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (7.9.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (5.1.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (4.3.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.11.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import_ipynb) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n",
            "Installing collected packages: jedi, import-ipynb\n",
            "Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pickle-mixin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciWG0jpgHBGd",
        "outputId": "78abf541-5dee-4c9e-b212-b2f280e7405f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle-mixin\n",
            "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: pickle-mixin\n",
            "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=6006 sha256=c4392503ee331df93d8097e4e099232dfbefe15caf03d0609b48c75d117aaf13\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a4/6c/83bfbc3b94f1bb43d634b07a6a893fd437a45c58b29aea5142\n",
            "Successfully built pickle-mixin\n",
            "Installing collected packages: pickle-mixin\n",
            "Successfully installed pickle-mixin-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Classifer-1\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input,Lambda,Dense,Flatten\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "Image_Size=[224,224]\n",
        "train_path='chest_xray/train'\n",
        "test_path='chest_xray/test'\n",
        "def load_normal(norm_path):\n",
        "  norm_files = np.array(os.listdir(norm_path))\n",
        "  norm_labels = np.array(['normal']*len(norm_files))\n",
        "  norm_images = []\n",
        "  for image in tqdm(norm_files):\n",
        "    image = cv2.imread(norm_path + image)\n",
        "    image = cv2.resize(image, dsize=(224,224))\n",
        "    norm_images.append(image)\n",
        "    norm_images = np.array(norm_images)\n",
        "  return norm_images, norm_labels\n",
        "def load_pneumonia(pneu_path):\n",
        "  pneu_files = np.array(os.listdir(pneu_path))\n",
        "  pneu_labels = np.array(['pneumonia']*len(pneu_files))\n",
        "  pneu_images = []\n",
        "  for image in tqdm(pneu_files):\n",
        "    image = cv2.imread(pneu_path + image)\n",
        "    image = cv2.resize(image, dsize=(224,224))\n",
        "    pneu_images.append(image)  \n",
        "    pneu_images = np.array(pneu_images)\n",
        "  return pneu_images, pneu_labels\n",
        "  norm_images, norm_labels = load_normal('chest_xray/train/NORMAL/')\n",
        "  pneu_images, pneu_labels = load_pneumonia('chest_xray/train/PNEUMONIA/')\n",
        "  X_train = np.append(norm_images, pneu_images, axis=0)\n",
        "  y_train = np.append(norm_labels, pneu_labels)\n",
        "  np.unique(y_train, return_counts=True)\n",
        "  norm_images_test, norm_labels_test = load_normal('chest_xray/test/NORMAL/')\n",
        "  pneu_images_test, pneu_labels_test = load_pneumonia('chest_xray/test/PNEUMONIA/')\n",
        "  X_test = np.append(norm_images_test, pneu_images_test, axis=0)\n",
        "  y_test = np.append(norm_labels_test, pneu_labels_test)\n",
        "  y_train = y_train[:, np.newaxis]\n",
        "  y_test = y_test[:, np.newaxis]\n",
        "  one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "  y_train_one_hot = one_hot_encoder.fit_transform(y_train)\n",
        "  y_test_one_hot = one_hot_encoder.transform(y_test)\n",
        "  vgg=DenseNet121(input_shape=Image_Size+[3],weights='imagenet',include_top=False)\n",
        "  for layer in vgg.layers:\n",
        "    layer.trainable=False\n",
        "  x=Flatten()(vgg.output)\n",
        "  x=Dense(256,activation='relu')(x)\n",
        "  prediction=Dense(2,activation='softmax')(x)\n",
        "  model=Model(inputs=vgg.input,outputs=prediction)\n",
        "  model.summary()\n",
        "  model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy'])\n",
        "  train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True)\n",
        "  test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "  train_datagen.fit(X_train)\n",
        "  train_gen = train_datagen.flow(X_train, y_train_one_hot, batch_size=32)\n",
        "  X_test=X_test/255\n",
        "  from keras.callbacks import EarlyStopping\n",
        "  from keras.callbacks import ModelCheckpoint\n",
        "  es = EarlyStopping(monitor= \"val_accuracy\" , min_delta= 0.01, patience= 3, verbose=2)\n",
        "  mc = ModelCheckpoint(filepath=\"specialimp.h5\", monitor=\"val_accuracy\", verbose=2,\n",
        "  save_best_only= True)\n",
        "  r=model.fit(\n",
        "  train_gen,\n",
        "  validation_data=(X_test,y_test_one_hot),\n",
        "  epochs=35,\n",
        "  steps_per_epoch=20,\n",
        "  validation_steps=7,callbacks=[mc])\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.title('Accuracy scores')\n",
        "  plt.xlabel('number of epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.plot(r.history['accuracy'])\n",
        "  plt.plot(r.history['val_accuracy'])\n",
        "  plt.legend(['accuracy', 'val_accuracy'])\n",
        "  plt.show()\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.title('Loss value')\n",
        "  plt.xlabel('number of epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.plot(r.history['loss'])\n",
        "  plt.plot(r.history['val_loss'])\n",
        "  plt.legend(['loss', 'val_loss'])\n",
        "  plt.show()\n",
        "  ## load only the best model\n",
        "  from keras.models import load_model\n",
        "  model1 = load_model(\"specialimp.h5\")\n",
        "  predictions = model1.predict(X_test)\n",
        "  predictions = one_hot_encoder.inverse_transform(predictions)\n",
        "  cm = confusion_matrix(y_pred=predictions,y_true=y_test)\n",
        "  classnames = ['normal', 'pneumonia']\n",
        "  plt.figure(figsize=(7,7))\n",
        "  plt.title('Confusion matrix')\n",
        "  sns.set(font_scale=3)\n",
        "  sns.heatmap(cm, cbar=False, xticklabels=classnames, yticklabels=classnames, fmt='d',\n",
        "  annot=True, cmap=plt.cm.Blues)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "528BMPVTHS6-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Classifer-2\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "def load_pneumonia(pneu_path):\n",
        "  pneu_files = np.array(os.listdir(pneu_path))\n",
        "  pneu_labels = np.array([pneu_file.split('_')[1] for pneu_file in pneu_files])\n",
        "  pneu_images = []\n",
        "  for image in tqdm(pneu_files):\n",
        "    image = cv2.imread(pneu_path + image)\n",
        "    image = cv2.resize(image, dsize=(224,224))\n",
        "    pneu_images.append(image)\n",
        "    pneu_images = np.array(pneu_images)\n",
        "  return pneu_images, pneu_labels\n",
        "  bacteria_images, bacteria_labels = load_pneumonia('chest_xray/train/BACTERIA/')\n",
        "  virus_images, virus_labels = load_pneumonia('chest_xray/train/VIRUS/')\n",
        "  x_train = np.append(bacteria_images, virus_images, axis=0)\n",
        "  y_train = np.append(bacteria_labels, virus_labels)\n",
        "  np.unique(y_train, return_counts=True)\n",
        "  fig, axes = plt.subplots(ncols=7, nrows=2, figsize=(16, 4))\n",
        "  indices = np.random.choice(len(x_train), 14)\n",
        "  counter = 0\n",
        "  for i in range(2):\n",
        "    for j in range(7):\n",
        "      axes[i,j].set_title(y_train[indices[counter]])\n",
        "      axes[i,j].imshow(x_train[indices[counter]], cmap='gray')\n",
        "      axes[i,j].get_xaxis().set_visible(False)\n",
        "      axes[i,j].get_yaxis().set_visible(False)\n",
        "      counter += 1\n",
        "  plt.show()\n",
        "  bacteria_images_test, bacteria_labels_test = load_pneumonia('chest_xray/test/BACTERIA/')\n",
        "  virus_images_test, virus_labels_test = load_pneumonia('chest_xray/test/VIRUS/')\n",
        "  x_test = np.append(bacteria_images_test, virus_images_test, axis=0)\n",
        "  y_test = np.append(bacteria_labels_test, virus_labels_test)\n",
        "  y_train = y_train[:, np.newaxis]\n",
        "  y_test = y_test[:, np.newaxis]\n",
        "  one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "  y_train_one_hot = one_hot_encoder.fit_transform(y_train)\n",
        "  y_test_one_hot = one_hot_encoder.transform(y_test)    \n",
        "  datagen = ImageDataGenerator(\n",
        "  rotation_range = 10,\n",
        "  zoom_range = 0.1,\n",
        "  width_shift_range = 0.1,\n",
        "  height_shift_range = 0.1)\n",
        "  datagen.fit(x_train)\n",
        "  train_gen = datagen.flow(x_train, y_train_one_hot, batch_size=32)\n",
        "  input1 = Input(shape=(x_train.shape[1], x_train.shape[2], 3))\n",
        "  cnn = Conv2D(16, (3, 3), activation='relu', strides=(1, 1),\n",
        "  padding='same')(input1)\n",
        "  cnn = Conv2D(32, (3, 3), activation='relu', strides=(1, 1),\n",
        "  padding='same')(cnn)\n",
        "  cnn = MaxPool2D((2, 2))(cnn)\n",
        "  cnn = Conv2D(16, (2, 2), activation='relu', strides=(1, 1),\n",
        "  padding='same')(cnn)\n",
        "  cnn = Conv2D(32, (2, 2), activation='relu', strides=(1, 1),\n",
        "  padding='same')(cnn)\n",
        "  cnn = MaxPool2D((2, 2))(cnn)\n",
        "  cnn = Flatten()(cnn)\n",
        "  cnn = Dense(100, activation='relu')(cnn)\n",
        "  cnn = Dense(50, activation='relu')(cnn)\n",
        "  output1 = Dense(2, activation='softmax')(cnn)\n",
        "  model = Model(inputs=input1, outputs=output1)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "  optimizer='adam', metrics=['accuracy'])\n",
        "  # implementing early stopping and model check point\n",
        "  from keras.callbacks import EarlyStopping\n",
        "  from keras.callbacks import ModelCheckpoint\n",
        "  es = EarlyStopping(monitor= \"val_accuracy\" , min_delta= 0.01, patience= 3, verbose=1)\n",
        "  mc = ModelCheckpoint(filepath=\"hyu.h5\", monitor=\"val_accuracy\", verbose=2,\n",
        "  save_best_only= True)\n",
        "  history = model.fit_generator(train_gen,steps_per_epoch=10, epochs=100,\n",
        "  validation_data=(x_test, y_test_one_hot),callbacks=[mc])\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.title('Accuracy scores')\n",
        "  plt.xlabel('number of epoch')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.legend(['accuracy', 'val_accuracy'])\n",
        "  plt.show()\n",
        "  plt.figure(figsize=(8,6))\n",
        "  plt.title('Loss value')\n",
        "  plt.xlabel('number of epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.legend(['loss', 'val_loss'])\n",
        "  plt.show()\n",
        "  ## load only the best model\n",
        "  from keras.models import load_model\n",
        "  model1 = load_model(\"hyu.h5\")\n",
        "  predictions = model.predict(x_test)\n",
        "  predictions = one_hot_encoder.inverse_transform(predictions)\n",
        "  cm = confusion_matrix(y_test, predictions)\n",
        "  classnames = ['bacteria', 'virus']\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.title('Confusion matrix')\n",
        "  sns.set(font_scale=3)\n",
        "  sns.heatmap(cm, cbar=False, xticklabels=classnames, yticklabels=classnames, fmt='d',\n",
        "  annot=True, cmap=plt.cm.Blues)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.show()\n",
        "  from sklearn.metrics import classification_report as jk\n",
        "  print(jk(y_test, predictions))"
      ],
      "metadata": {
        "id": "231I79JGHh56"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzNEiHlqNP2Z",
        "outputId": "982dab07-e8e9-40df-b065-b441a62f02e0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tk\n",
            "  Downloading tk-0.1.0-py3-none-any.whl (3.9 kB)\n",
            "Installing collected packages: tk\n",
            "Successfully installed tk-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## User Interface\n",
        "import tkinter as tk\n",
        "from tkinter import *\n",
        "from PIL import Image,ImageTk\n",
        "from tkinter import filedialog\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image as pimage\n",
        "import numpy as np\n",
        "window= tk.Tk()\n",
        "window.geometry(\"700x150\")\n",
        "path=\"\"\n",
        "window.geometry(\"1000x675\")\n",
        "window.resizable(False,False)\n",
        "window.title(\"Pneumonia Detection And Classification\")\n",
        "window.configure(background='black')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "bIfauz8iLFd-",
        "outputId": "c588b3cb-8c18-48d8-d0e9-c7dc7a8e8764"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-98fe63a80f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"700x150\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2259\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "SK-R83zlN5K9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24I9nIJWMv66"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}